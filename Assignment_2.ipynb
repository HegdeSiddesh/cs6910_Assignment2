{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HegdeSiddesh/cs6910_Assignment2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment 2: \n",
        "The goal of this assignment is threefold:        \n",
        "(i) train a CNN model from scratch and learn how to tune the hyperparameters and visualise filters      \n",
        "(ii) finetune a pre-trained model just as you would do in many real world applications              \n",
        "(iii) use an existing pre-trained model for a cool application.\n"
      ],
      "metadata": {
        "id": "UfZa3C_cOHPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "suzvN-4y8S-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "w9orOezcSkAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZijUCAyFx5_s"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(137) # To ensure that the random number generated are the same for every iteration\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "!pip install --upgrade wandb\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Dense, Flatten, InputLayer\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Activation\n",
        "from wandb.keras import WandbCallback\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDIk96MJvcIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9bfce985-da2a-44b2-ede6-db7ecaec8135"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download and unzip the iNaturalist dataset\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip -q /content/nature_12K.zip"
      ],
      "metadata": {
        "id": "uE9tJ8y82FAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f659200a-3439-401a-b36a-770f1fc3c3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-25 14:01:41--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 74.125.140.128, 108.177.15.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G  59.3MB/s    in 85s     \n",
            "\n",
            "2022-03-25 14:03:07 (43.1 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "Zoo_r2_XsELT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "1J0VAy5isLQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part A: Training from scratch"
      ],
      "metadata": {
        "id": "IgX7t12PVVOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 1 \n",
        "\n",
        "Build a small CNN model consisting of  5 convolution layers. Each convolution layer would be followed by a ReLU activation and a max pooling layer. Here is sample code for building one such conv-relu-maxpool block in keras.\n",
        "\n",
        "model = Sequential()     \n",
        "model.add(Conv2D(16, (3, 3)input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "After 5 such conv-relu-maxpool blocks of  layers you should have one dense layer followed by the output layer containing 10 neurons (1 for each of the 10 classes).    \n",
        "\n",
        "The input layer should be compatible with the images in the iNaturalist dataset.\n",
        "The code should be flexible such that the number of filters, size of filters and activation function in each layer can be changed. You should also be able to change the number of neurons in the dense layer.\n",
        "\n",
        "(a) What is the total number of computations done by your network? (assume m filters in each layer of size kxk and n neurons in the dense layer)\n",
        "\n",
        "(b) What is the total number of parameters in your network? (assume m filters in each layer of size kxk and n neurons in the dense layer)"
      ],
      "metadata": {
        "id": "px0CpWhLzLGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9lO-8eMG5joZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Assignment_2\", entity=\"hithesh-sidhesh\", name=\"Question_1\")"
      ],
      "metadata": {
        "id": "JapS9yHc8lzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To find the shape of the image\n",
        "os.chdir(\"/content/inaturalist_12K/train/Amphibia\")\n",
        "img=plt.imread(\"0012ec13b97dfbfb3dd5de8c3da95555.jpg\")\n",
        "print(img.shape)\n",
        "print(\"The image consists of %i pixels\" % (img.shape[0] * img.shape[1]))\n",
        "plt.imshow(img);"
      ],
      "metadata": {
        "id": "Xtmfzkmu0hJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZGh0_vIRXEY"
      },
      "outputs": [],
      "source": [
        "#Splitting training data into train and validation sets\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,validation_split=0.1)\n",
        "IMG_SIZE = (128,128)\n",
        "\n",
        "#CONFIG = wandb.config\n",
        "#BATCH_SIZE = CONFIG.batch_size\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/inaturalist_12K/train',\n",
        "         target_size=IMG_SIZE,\n",
        "        subset = 'training',\n",
        "            batch_size=32,\n",
        "            class_mode='categorical',\n",
        "            shuffle = True,\n",
        "        seed = 137)\n",
        "print('TRAINING')\n",
        "print('Number of samples', train_generator.samples)\n",
        "print('Names of classes', train_generator.class_indices)\n",
        "print('Number of classes', len(train_generator.class_indices))\n",
        "print('Number of samples per class', int(train_generator.samples / len(train_generator.class_indices) ))\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/inaturalist_12K/train',\n",
        "         target_size=IMG_SIZE,\n",
        "            subset = 'validation',\n",
        "            batch_size=32,\n",
        "            class_mode='categorical',\n",
        "            shuffle = True,\n",
        "        seed = 137)\n",
        "print('VALIDATION')\n",
        "print('Number of samples', validation_generator.samples)\n",
        "print('Names of classes', validation_generator.class_indices)\n",
        "print('Number of classes', len(validation_generator.class_indices))\n",
        "print('Number of samples per class', int(validation_generator.samples / len(validation_generator.class_indices) ))\n",
        "\n",
        "#Test data\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/inaturalist_12K/val',\n",
        "         target_size=IMG_SIZE,\n",
        "            batch_size=32,\n",
        "            class_mode='categorical',\n",
        "            shuffle = True,\n",
        "        seed = 137)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(number_of_conv_layers,number_of_filters,kernel_size,image_shape,activation_conv,pool_size,neurons_dense,activation_dense,neurons_output,activation_output):\n",
        "  model = Sequential()\n",
        "  for i in range(0,number_of_conv_layers):\n",
        "    model.add(Conv2D(number_of_filters[i], kernel_size[i] , input_shape= image_shape))\n",
        "    model.add(Activation(activation_conv[i]))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size[i]))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(neurons_dense[i], activation=activation_dense[i]))\n",
        "  model.add(layers.Dense(neurons_output, activation=activation_output))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "hq4f7Q_RjkZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_conv_layers=5\n",
        "number_of_filters=[128]*number_of_conv_layers\n",
        "kernel_size=[(3,3)]*number_of_conv_layers\n",
        "image_shape=(128,128,3)\n",
        "activation_conv=['relu','relu','relu','relu','relu']\n",
        "pool_size=[(2,2)]*number_of_conv_layers\n",
        "neurons_dense_layer=[64]*number_of_conv_layers\n",
        "activation_dense=['relu','relu','relu','relu','relu']\n",
        "no_of_output_classes=10\n",
        "activation_output='softmax'\n",
        "\n",
        "model=build_model(number_of_conv_layers,number_of_filters,kernel_size,image_shape,activation_conv,pool_size,neurons_dense_layer,activation_dense,no_of_output_classes,activation_output)\n",
        "model.fit(train_generator,\n",
        "          epochs=2,\n",
        "          validation_data=validation_generator\n",
        "          )\n",
        "\n"
      ],
      "metadata": {
        "id": "DuxJB1SV8lI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator , verbose=2)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_upvQ6zeP4l7",
        "outputId": "afddc3a4-e790-4e83-a7f3-b64087b6709e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 - 23s - loss: 2.1244 - accuracy: 0.2140 - 23s/epoch - 373ms/step\n",
            "0.21400000154972076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4MuTlxYlZCH"
      },
      "source": [
        "##Question 2\n",
        "\n",
        "You will now train your model using the iNaturalist dataset. The zip file contains a train and a test folder. Set aside 10% of the training data for hyperparameter tuning. Make sure each class is equally represented in the validation data. Do not use the test data for hyperparameter tuning. \n",
        "\n",
        "Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore\n",
        "\n",
        "* number of filters in each layer : 32, 64, ...  \n",
        "* filter organisation: same number of filters in all layer, doubling in each subsequent layer, halving in each subsequent layer, etc   \n",
        "* data augmentation (easy to do in keras): Yes, No      \n",
        "* dropout: 20%, 30% (btw, where will you add dropout? you should read up a bit on this)     \n",
        "* batch normalisation: Yes, No      \n",
        "\n",
        "Based on your sweep please paste the following plots which are automatically generated by wandb:     \n",
        "* accuracy v/s created plot (I would like to see the number of experiments you ran to get the best configuration).          \n",
        "* parallel co-ordinates plot              \n",
        "* correlation summary table (to see the correlation of each hyperparameter with the loss/accuracy)             \n",
        "\n",
        "Also write down the hyperparameters and their values that you sweeped over. Smart strategies to reduce the number of runs while still achieving a high accuracy would be appreciated. Write down any unique strategy that you tried.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',  # grid, random\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values': [5, 10]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'image_size': {\n",
        "            'values': [256, 512]\n",
        "        },\n",
        "        'no_of_conv_layers': {\n",
        "            'values': [5, 6]\n",
        "        },\n",
        "        'no_of_filters': {\n",
        "            'values': [16, 32, 64, 128]\n",
        "        },\n",
        "        'kernel_size': {\n",
        "            'values': [3, 4]\n",
        "        },\n",
        "        'dense_layer_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'no_of_dense_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'filter_organization': {\n",
        "            'values': ['same', 'double', 'halve']\n",
        "        },\n",
        "        'data_augmentation': {\n",
        "            'values': ['yes', 'no']\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [None, 0.15, 0.2, 0.25, 0.3]\n",
        "        },\n",
        "        'batch_normalization': {\n",
        "            'values': ['yes', 'no']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "PqqLqVAi34Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(activation_function_conv, activation_function_dense, num_filters, shape_of_filters_conv, shape_of_filters_pool, batch_norm_use, fc_layer, dropout):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(num_filters[0], shape_of_filters_conv[0], input_shape=input_image_shape))\n",
        "    if batch_norm_use:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_function_conv[0]))\n",
        "    model.add(MaxPool2D(pool_size=shape_of_filters_pool[0], strides = (2, 2)))\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        model.add(Conv2D(num_filters[i], shape_of_filters_conv[i]))\n",
        "        if batch_norm_use:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(activation_function_conv[i]))\n",
        "        model.add(MaxPool2D(pool_size=shape_of_filters_pool[i], strides = (2, 2)))\n",
        "\n",
        "    model.add(Flatten()) # The flatten layer is essential to convert the feature map into a column vector\n",
        "    model.add(Dense(fc_layer, activation=activation_function_dense))\n",
        "    model.add(Dropout(dropout)) # For regularization\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "def build_model(number_of_conv_layers,number_of_filters,kernel_size,image_shape,activation_conv,pool_size,neurons_dense,activation_dense,neurons_output,activation_output):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(num_filters[0], shape_of_filters_conv[0], input_shape=input_image_shape))\n",
        "    if batch_norm_use:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_function_conv[0]))\n",
        "    model.add(MaxPool2D(pool_size=shape_of_filters_pool[0], strides = (2, 2)))\n",
        "  for i in range(0,number_of_conv_layers):\n",
        "    model.add(Conv2D(number_of_filters[i], kernel_size[i] , input_shape= image_shape))\n",
        "    model.add(Activation(activation_conv[i]))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size[i]))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(neurons_dense[i], activation=activation_dense[i]))\n",
        "  model.add(layers.Dense(neurons_output, activation=activation_output))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "LADKicoFkE0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  # Default values for hyper-parameters\n",
        "    config_defaults = {\n",
        "        \"data_aug\": True,\n",
        "        \"train_batch_size\": 128,\n",
        "        \"batch_norm_use\": True,\n",
        "        \"dropout\": 0,\n",
        "        \"num_filters\": [16, 32, 64, 128, 256],\n",
        "        \"fc_layer\": 256,\n",
        "        \"shape_of_filters_conv\": [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    \n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "with wandb.init(project='Assignment_2',config = sweep_config, name=\"Question_2\"):\n",
        "      config = wandb.init().config"
      ],
      "metadata": {
        "id": "5XiNFLDA34Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (1,5):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkgPS3VdHG5",
        "outputId": "b79633d2-f091-4490-a44f-071b982d8ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = [(3,)*2]\n",
        "print(kernel_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMuTdBFBLgaL",
        "outputId": "7037248b-4b99-43da-eb00-a70b2541cfc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3, 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train)"
      ],
      "metadata": {
        "id": "yKYZDNpGKsq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}